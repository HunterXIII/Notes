# 1. Алгоритм. Память и время как ресурсы.

## Алгоритм
**Алгоритм** - это набор шагов или инструкций, необходимых для решения задачи
ИЛИ
**Алгоритм** - это набор конечного числа правил, задающих последовательность выполнения операций компьютерной программой для решения задачи определённого типа

**Свойства алгоритма:**
- **Конечность.** Алгоритм всегда должен заканчиваться после выполнения конечного числа шагов.
- **Определённость.** Действия, которые нужно выполнить, должны быть строго и недвусмысленно определены для каждого возможного случая.
- **Вввод.** Алгоритм имеет некоторое (возможно, равное нулю) число входных данных.
- **Вывод.** У алгоритма есть одно или несколько выходных данных , т. е. величин, имеющих вполне определенную связь с входными данными.
- **Эффективность.** Алгоритм обычно считается эффективным, если все его операторы достаточно просты для того, чтобы их можно было точно выполнить в течение конечного промежутка времени с помощью карандаша и бумаги.

## Память
Для анализа алгоритма обычно используется анализ пространственной сложности алгоритма, чтобы оценить необходимую память времени исполнения как функцию от размера входа. Результат обычно выражается в терминах **«O» большое**.

Существует **четыре аспекта использования памяти**:
- Количество памяти, необходимой для **хранения кода алгоритма.**
- Количество памяти, необходимое для **входных данных**.
- Количество памяти, необходимое **для любых выходных данных** (некоторые алгоритмы, такие как сортировки, часто переставляют входные данные и не требуют дополнительной памяти для выходных данных).
- Количество памяти, необходимое **для вычислительного процесса** во время вычислений (сюда входят именованные переменные и любое стековое пространство, необходимое для вызова подпрограмм, которое может быть существенным при использовании рекурсии).

## Время
Для анализа алгоритма обычно используется анализ временной сложности алгоритма, чтобы оценить время работы как функцию от размера входных данных. Результат обычно выражается в терминах «O» большое
> Не выражается в секундах, минутах или часах, так как эти величины зависят от мощности железа, на котором запускается алгоритм. Поэтому время считают в количестве **итераций (операций)**.  

--- 
# 2. O-символика как инструмент оценки ресурсов, различные асимптотики (логарифм, полином, экспонента).

**"О" большое** - Это математическое обозначение для сравнения асимптотического поведения (асимптотики) функций. Используются в различных разделах математики, но активнее всего — в математическом анализе, теории чисел и комбинаторике, а также в информатике и теории алгоритмов. Под асимптотикой понимается характер изменения функции при стремлении её аргумента к определённой точке.

Запись $О(f(n))$ означает, что с увеличением параметра, характеризующего количество входной информации алгоритма, время работы алгоритма будет возрастать не быстрее, чем $f(n)$, умноженная на некоторую константу.

$f(n) = O(1)$ константа
$f(n) = O(log(n))$ логарифмический рост
$f(n) = O(n)$ линейный рост
$f(n) = O(n*log(n))$ квазилинейный рост
$f(n) = O(n^m)$ полиномиальный рост
$f(n) = O(2^n)$ экспоненциальный рост - самый худший
$f(n) = O(n!)$ сначала нормально, потом резко растет 


![[Pasted image 20250102124646.png]]
![[Pasted image 20250102124738.png]]
![[Pasted image 20250102124804.png]]
![[Pasted image 20250102124818.png]]
![[Pasted image 20250102124827.png]]

---
# 3. Метод математической индукции, использование для доказательства оценок

**Математическая индукция** - если утверждение истинно в одном случае, то оно окажется истинным и в следующем за ним случае.

**Математическая индукция** — это метод доказательства, который состоит из двух основных шагов:
1. **База индукции**: Необходимо показать, что утверждение $P(1)$ верно.
2. **Шаг индукции**: Нужно доказать, что если утверждение верно для некоторых целых положительных чисел $P(1),P(2),…,P(n)$, то оно также верно для следующего числа $P(n+1)$. Это доказательство должно быть справедливо для любого целого положительного n.

> P.S. *Не очень понятно, что конкретно нужно*

---
# 4. Алгоритмы для работы с большими числами: сложение, умножение, быстрое возведение в степень

**Необходимость использования:**
- Ограничения на объем типов данных
- Время выполнения операций на больших числах
- Использование встроенных функций ограниченно типами данных и особенностями реализации
## Сложение
1. Числа представлены в виде массивов, состоящих из "коротких" чисел (играют роль цифр) 
2. Массив для результата и переменная для переноса (изначально 0) 
3. Складываются разряды двух чисел с учётом переноса перенос
4. Если после сложения всех разрядов остался перенос, он добавляется вперёд числа (к старшему разряду)
## Умножение большого числа на малое 
Аналогично сложению, только вместо сложения разрядов(шаг 3) происходит перемножение, и также учитывается сложение с переносом. 
## Умножение большого числа на большое
Состоит из умножения на малое число и сложения. 
1. Одно число умножается на каждый разряд другого (умножение большого числа на малое)
2. Промежуточные результаты складывается (учитывая "положения числа", т. е. 25 * 25 это 125 + 50***0***) 
## Быстрое возведение в степень
1. Если степень n чётная, основание возводится в квадрат, а степень делится на 2.
2. Если степень n нечётная, основание умножается на результат, а степень уменьшается на 1.
3. Процесс повторяется до тех пор, пока k>0.

---
# 5. Арифметика по модулю: сложение, умножение, возведение в степень

Если два целых числа a и b при делении на m дают одинаковые остатки, то они называются **сравнимыми (или равноостаточными) по модулю числа m. a ≡ b (mod m)**
сравнимыми (или равноостаточными) по модулю числа m. a ≡ b (mod m)

**Операции по модулю:**
(A + B) mod C = (A mod C + B mod C) mod C 
(A * B) mod C = (A mod C * B mod C) mod C 
A^B mod C = ( (A mod C)^B ) mod C

--- 
# 6. Алгоритм Евклида, расширенный алгоритм Евклида.

**Алгоритм Евклида** - находит **наибольший общий делитель** для чисел m и n
1. Разделим $m$ на $n$, и пусть остаток от деления будет равен $r$ (где $0 ≤ r < n$).
2. Если $r = 0$, то выполнение алгоритма прекращается; $n$ — искомое значение.
3. Присвоить $m = n, n = r$ и вернуться к шагу 1.
```python
def euclidus(m, n):
    while n:
        m, n = n, m % n
    return m
```

**Расширенный алгоритм Евклида** 
В то время как "обычный" алгоритм Евклида просто находит наибольший общий делитель двух чисел m и n, расширенный алгоритм Евклида находит помимо НОД также коэффициенты x и y такие, что:
$$ x * m + y * n = НОД(m, n) $$
Т.е. он находит коэффициенты, с помощью которых НОД двух чисел выражается через сами эти числа.

```python
def extended_euclidus(m, n):
    if n == 0:
        return m, 1, 0
    d, x1, y1 = extended_euclidus(n, m % n)
    x = y1
    y = x1 - (m // n) * y1
    return d, x, y
```

---
# 7. **Проверка чисел на простоту, решето Эратосфена.**

**Простое число** - число, которое делится нацело только на себя и на 1.

Соответственно, чтобы проверить число n на простоту достаточно перебрать все числа от 2 до числа n. Можно ускорить процесс, перебрав числа только до *корня n*. 

>Число 64 делится на 2, 4, 8, 16, 32.
>64 = 8. Число 8 делится на 2, 4.
  Всё дело в том, что если расписывать число 64 как произведение двух множителей, то получим следующую ситуацию:
    2 * 32 = 64
	4 * 16 = 64
	8 * 8 = 64
	16 * 4 = 64
	32 * 2 = 64
  Нетрудно видеть, что после 8 * 8 = 64 варианты повторяются. А 8 - как раз корень из числа 64. Поэтому достаточно проверить лишь числа до n включительно, так как корень из числа, если окажется целым, точно будет делителем числа (очевидно почему).

```python
def is_prime(n):
    for i in range(2, int(n**0.5)+1):
        if not n % i:
            return False
    return True
```

**Решето Эратосфена** - алгоритм нахождения всех простых чисел до некоторого целого числа n. 
Принцип простой: строим список чисел от 2 до n, после чего удаляем из него все составные числа.
Составное число - число, имеющее делители помимо 1 и числа n. Т.е. все числа, кроме простых.
Если более подробно, то алгоритм построения решета Эратосфена выглядит так:
Выписать подряд все целые числа от двух до n (2, 3, 4, …, n).
Пусть переменная p изначально равна двум — первому простому числу.
Зачеркнуть в списке числа от 2p до n, считая шагами по p (это будут числа, кратные p: 2p, 3p, 4p, …).
Найти первое незачёркнутое число в списке, большее чем p, и присвоить значению переменной p это число.
Повторять шаги 3 и 4, пока возможно.
```python
def eratosthenes(n):
    arr = [i for i in range(n + 1)]
    arr[1] = 0
    for p in arr:
        if p != 0:
            arr[2*p::p] = [0] * len(arr[2*p::p])
    return [i for i in arr if i != 0]
``` 

---
# 8. **Криптография: схемы с закрытым ключом, RSA.**

**RSA (аббревиатура от фамилий Rivest, Shamir и Adleman)** — криптографический алгоритм с открытым ключом, основывающийся на вычислительной сложности задачи факторизации больших полупростых чисел.

Например, 592939 * 592967 = 351593260013. Но как имея только число 351593260013 узнать числа 592939 и 592967? Это называется «сложность задачи факторизации произведения двух больших простых чисел», т.е. в одну сторону просто, а в обратную невероятно сложно.

RSA использует два ключа — открытый (публичный) и закрытый (приватный). Открытый ключ может быть доступен всем и используется для шифрования сообщений. Закрытый ключ хранится в секрете и используется для расшифровки полученных сообщений
## Генерация ключей
1. Выбираем два случайных простых числа p и q
2. Вычисляем их произведение: N = p * q
3. Вычисляем функцию Эйлера: 𝜑(N) = (p-1) * (q-1)
4. Выбираем число e (обычно простое, но необязательно), которое меньше
𝜑(N) и является взаимно простым с 𝜑(N) (не имеющих общих делителей
друг с другом, кроме 1).
5. Ищем число d, обратное числу e по модулю 𝜑(N). Т.е. остаток от деления
$(d*e)$ и 𝜑(N) должен быть равен 1. Найти его можно через расширенный
алгоритм Евклида.
e и n – открытый ключ
d и n – закрытый ключ

---
# 9. **Квадратичные сортировки (вставками, выбором минимума).**
## Пузырьковая 
![[Pasted image 20250103114721.png]]
```python
def bubble_sort(arr: list) -> list:
    for j in range(len(arr) - 1):
        f = False
        for i in range(len(arr) - 1 - j):
            if arr[i] > arr[i+1]:
                arr[i], arr[i+1] = arr[i+1], arr[i]
                f = True
        if not f:
            break
```
## Вставками
![[Pasted image 20250103114852.png]]
```python
def insert_sort(arr):
    for i in range(1, len(arr)):
        j = i
        while j > 0 and arr[j] < arr[j-1]:
            arr[j], arr[j-1] = arr[j-1], arr[j]
            j -= 1
```

С бинарным поиском
```python
def insertion_sort(arr: list) -> list:    
    for i in range(1, len(arr)):
        left, right = 0, i - 1
        mid = (left + right) // 2
           
        while left < right:
            if arr[i] == arr[mid]:
                break
            elif arr[i] < arr[mid]:
                right = mid
            else:
                left = mid + 1
            mid = (left + right) // 2
           
        if arr[i] > arr[mid]:
            mid += 1
           
        arr[mid], arr[mid + 1: i + 1] = arr[i], arr[mid:i]
```

---
# 10.  **Метод «разделяй и властвуй». Бинарный поиск.**

## Метод "разделяй и властвуй"
«**Разделяй и властвуй»** в информатике — схема разработки алгоритмов, заключающаяся в рекурсивном разбиении решаемой задачи на две или более подзадачи того же типа, но меньшего размера, и комбинировании их решений для получения ответа к исходной задаче; разбиения выполняются до тех пор, пока все подзадачи не окажутся элементарными. Применяется в таких алгоритмах как бинарный (двоичный) поиск и сортировка слиянием.

## Бинарный поиск
![[Pasted image 20250103120031.png]]

---
# 11. Сортировка слиянием: наивная и эффективная реализация.

Суть:
1. Сортируемый массив разбивается на две части примерно одинакового размера. Рекурсивное разбиение задачи на меньшие происходит до тех пор, пока размер массива не достигнет единицы (любой массив длины 1 можно считать упорядоченным).
2. Каждая из получившихся частей сортируется отдельно, например — тем же самым алгоритмом;
3. Два упорядоченных массива половинного размера соединяются в один.
    1. На каждом шаге мы берем меньший из двух первых элементов подмассивов и записываем его в результирующий массив. Счётчики номеров элементов результирующего массива и подмассива, из которого был взят элемент, увеличиваем на 1.
    2. Когда один из подмассивов закончился, мы добавляем все оставшиеся элементы второго подмассива в результирующий массив.

Подвид наивной реализации, сверху-вниз:
```python
def top_down_merge_sort(A):
    if len(A) == 1:
        return A

    d = len(A) // 2
    left = top_down_merge_sort(A[:d])
    right = top_down_merge_sort(A[d:])

    return merge(left, right)
```

Еще подвид наивной реализации, снизу-вверх:
```python

def bottom_up_merge_sort(A):
    k = 1
    while k < len(A):
        for i in range(0, len(A)-k, 2*k):
            A[i:i+2*k] = merge(A[i:i+k], A[i+k:i+2*k])
        k *= 2

    return A
```

Наивная функция слияния
```python
 def merge(A, B):
    i, j, C = 0, 0, []
    while True:
        if A[i] < B[j]:
            C.append(A[i])
            i += 1
            if i == len(A):
                C.extend(B[j:])
                break
        else:
            C.append(B[j])
            j += 1
            if j == len(B):
                C.extend(A[i:])
                break
    return C
```

<mark style="background: #FF5582A6;">> P.S. Дописать про галопирование и chunking </mark>

---
# 12. Быстрая сортировка: понятие вероятностного алгоритма, время работы в среднем, простейший алгоритм, inplace-алгоритм.

**Быстрая сортировка,** сортировка Хоара (quicksort, qsort (по имени в стандартной библиотеке языка Си) — алгоритм сортировки, разработанный английским информатиком Тони Хоаром во время своей работы в МГУ в 1960 году.


Алгоритм:

1. Массив $a[l…r]$ разбивается на два (возможно пустых) подмассива $a[l…q]$ и $a[q+1…r]$ таких, что каждый элемент $a[l…q]$ меньше или равен $a[q]$, который в свою очередь, не превышает любой элемент подмассива $a[q+1…r]$. Индекс вычисляется в ходе процедуры разбиения.
2. Подмассивы $a[l…q]$ и $a[q+1…r]$ сортируются с помощью рекурсивного вызова процедуры быстрой сортировки.
3. Поскольку подмассивы сортируются на месте, для их объединения не требуются никакие действия: весь массив $a[l…r]$ оказывается отсортированным.


**Вероятностный алгоритм** – это такой алгоритм, который использует случайность для принятия решений. В случае быстрой сортировки это означает, что выбор опорного элемента (pivot) происходит почти случайно. Вероятностная природа позволяет избежать худших случаев при работе алгоритма.

## Простейшая реализация
```python
def quicksort(arr):
    if len(arr) <= 1:
        return arr
   
    pivot = arr[0]
    left = []
    right = []
    
    for x in arr[1:]:
        if x < pivot:
            left.append(x)
        else:
            right.append(x)
            
    return quicksort(left) + [pivot] + quicksort(right)
```

## In-place 
```python
def partition(array, low, high):
    pivot = array[high]
    i = low - 1

    for j in range(low, high):
        if array[j] <= pivot:
            i = i + 1
            array[i], array[j] = array[j], array[i]

    array[i + 1], array[high] = array[high], array[i + 1]
    return i + 1


def quicksort(array, low, high):
    if low < high:
        pi = partition(array, low, high)

        quicksort(array, low, pi - 1)
        quicksort(array, pi + 1, high)
```

Сложность:
- в среднем $O(n * log(n))$
- В худшем $O(n^2)$ - если выбран плохой опорный элемент

--- 
# 13. Динамическое программирование. Общие принципы динамического программирования. Восстановление ответа.

**Динамическое программирование** — способ решения сложных задач путём разбиения их на более простые подзадачи. Он применим к задачам с
оптимальной подструктурой, выглядящим как набор перекрывающихся
подзадач, сложность которых чуть меньше исходной. В этом случае время
вычислений, по сравнению с «наивными» методами, можно значительно
сократить.

**Метод динамического программирования сверху** (мемоизация, ленивая
динамика) — это простое запоминание результатов решения тех подзадач,
которые могут повторно встретиться в дальнейшем.

**Динамическое программирование снизу (табуляция)** включает в себя переформулирование сложной задачи в виде рекурсивной последовательности более простых подзадач.

Основная идея состоит в том, чтобы
1. свести задачу для к задаче для чисел,меньших, чем N
(с помощью формулы)
2. хранить все ответы в массиве
3. заполнить начало массива вручную (для которых
формула не работает)
4. обойти массив и заполнить ответы по формуле
5. вывести ответ откуда-то из этого массива

Восстановление ответа:
1. Хранить дополнительный массив с решением
2. По таблице понять какое решение принято

---
# 14. Скип???

---
# 15. **Дискретная задача о рюкзаке.**

![[Pasted image 20250104121728.png]]![[Pasted image 20250104121758.png]]
![[Pasted image 20250104121828.png]]

---
# 16. Редакционное расстояние. 

**Расстояние Левенштейна (редакционное расстояние или дистанция редактирования)** — это минимальное количество операций вставки одного символа, удаления одного символа и замены одного символа на другой, необходимых для превращения одной строки в другую. Нахождения расстояния Левенштейна аналогично нахождению НОП для двух строк, за исключением того, что мы ищем не максимальное, а минимальное количество.
```python
def levenshtein_distance(s1, s2):
    n, m = len(s1), len(s2)

    if n > m:
        s1, s2 = s2, s1
        n, m = m, n

    current_row = list(range(n + 1))

    for i in range(1, m + 1):
        previous_row, current_row = current_row, [i] + [0] * n
        for j in range(1, n + 1):
            add = previous_row[j] + 1
            delete = current_row[j - 1] + 1
            change = previous_row[j - 1]
            if s1[j - 1] != s2[i - 1]:
                change += 1
            current_row[j] = min(add, delete, change)

    return current_row[n]
```

---
# 17. Односвязный список, двусвязный список. 

**Линейный однонаправленный список** — это структура данных, состоящая из
элементов одного типа, связанных между собой последовательно посредством
указателей. Каждый элемент списка имеет указатель на следующий элемент.
Последний элемент списка указывает на None . Элемент, на который нет
указателя, является первым (головным) элементом списка. Здесь ссылка в
каждом узле указывает на следующий узел в списке. В односвязном списке
можно передвигаться только в сторону конца списка. Узнать адрес предыдущего
элемента, опираясь на содержимое текущего узла, невозможно.

В информатике линейный список обычно определяется как абстрактный тип
данных (АТД), формализующий понятие упорядоченной коллекции данных. На
практике линейные списки обычно реализуются при помощи массивов и связных
списков.

АТД нетипизированного изменяемого списка может быть определён как набор из
конструктора и основных операций:
- Операция, проверяющая список на пустоту.
- Три операции добавления объекта в список (в начало, конец или внутрь после любого (n-го) элемента списка);
- Операция, вычисляющая первый (головной) элемент списка;
- Операция доступа к списку, состоящему из всех элементов исходного списка, кроме первого

Характеристики
- Длина списка.Количество элементов в списке.
- Списки могут быть типизированными и нетипизированными. Если список типизирован, то тип его элементов задан, и все его элементы должны иметь типы, совместимые с заданным типом элементов списка.
- Список может быть сортированным или несортированным.
- В зависимости от реализации может быть возможен произвольный доступ к элементам списка.

**Двусвязный список (двунаправленный связный список)** - ссылки в каждом узле
указывают на предыдущий и на последующий узел в списке.

Как и односвязный список, двусвязный допускает только последовательный
доступ к элементам, но при этом дает возможность перемещения в обе стороны.

В этом списке проще производить удаление и перестановку элементов, так как
легко доступны адреса тех элементов списка, указатели которых направлены на
изменяемый элемент.

Применение связанных списков:
- Для построения более сложных структур данных.
- Для реализации файловых систем.
- Для формирования хэш-таблиц.
- Для выделения памяти в динамических структурах данных.

---
# 18. Стек. Очередь. Дек. 


## Стек

**Стек (stack — стопка)** — структура данных, представляющая из себя упорядоченный набор элементов, в которой добавление новых элементов и удаление существующих производится с одного конца, называемого вершиной стека. Притом первым из стека удаляется элемент, который был помещен туда последним, то есть в стеке реализуется стратегия «последним вошел — первым вышел» (last-in, first-out — LIFO).

Операции стека:
- `empty` — проверка стека на наличие в нем элементов,
- `push` (запись в стек) — операция вставки нового элемента,
- `pop` (снятие со стека) — операция удаления нового элемента.

Применение стека
- Для реализации рекурсии.
- Для вычислений постфиксных значений.
- Для временного хранения данных, например истории запросов или изменений.

## Очередь

**Очередь (queue)** — это структура данных, добавление и удаление элементов в которой происходит путём операций push и pop соответственно. Притом первым из очереди удаляется элемент, который был помещен туда первым, то есть в очереди реализуется принцип «первым вошел — первым вышел» (first-in, first-out — FIFO). У очереди имеется голова (head) и хвост (tail). Когда элемент ставится в очередь, он занимает место в её хвосте. Из очереди всегда выводится элемент, который находится в ее голове.

Очередь поддерживает следующие операции:
- `empty` — проверка очереди на наличие в ней элементов,
- `push` (запись в очередь) — операция вставки нового элемента,
- `pop` (снятие с очереди) — операция удаления нового элемента,
- `size` — операция получения количества элементов в очереди.

Применение очереди
- Для реализации очередей, например на доступ к определённому ресурсу.
- Для управления потоками в многопоточных средах.
- Для генерации значений.
- Для создания буферов.

## Дек

**Дек (deque — double ended queue)** — структура данных, представляющая из себя список элементов, в которой добавление новых элементов и удаление существующих производится с обоих концов. Эта структура поддерживает как FIFO, так и LIFO, поэтому на ней можно реализовать как стек, так и очередь. Дек можно воспринимать как двустороннюю очередь.

Дек имеет следующие операции:
- `empty` — проверка на наличие элементов,
- `pushBack` (запись в конец) — операция вставки нового элемента в конец,
- `popBack` (снятие с конца) — операция удаления конечного элемента,
- `pushFront` (запись в начало) — операция вставки нового элемента в начало,
- `popFront` (снятие с начала) — операция удаления начального элемента.

---
# 19. Куча


**Куча (heap)** — это полное двоичное дерево, удовлетворяющее свойству кучи: если узел $A$ — это родитель узла $B$, то ключ узла A больше либо равен ключу узла B.

- Если любой узел всегда больше дочернего узла (узлов), а ключ корневого узла является наибольшим среди всех остальных узлов, это **max-куча**.
- Если любой узел всегда меньше дочернего узла (узлов), а ключ корневого узла является наименьшим среди всех остальных узлов, это **min-куча**.

Применяется для:
- Пирамидальной сортировки
- Алгоритмы поиска
- Алгоритмы на графах (Дейкстры, Прима)
- Очереди с приоритетом

Полная и почти полная бинарная куча может быть представлена очень эффективным способом с помощью индексного массива. Первый (или последний) элемент будет содержать корень. Следующие два элемента массива содержат узлы-потомки корня. Следующие четыре элемента содержат четверых потомков от двух узлов — потомков корня, и так далее. Таким образом, потомки узла уровня n будут расположены на позициях `2n` и `2n+1` для массива, индексируемого с единицы, или на позициях `2n+1` и `2n+2` для массива, индексируемого с нуля.

| Операция    | найти мин. | добавить | удалить мин. | уменьшить ключ | слияние |
| ----------- | :--------: | :------: | :----------: | :------------: | :-----: |
| Асимптотика |    O(1)    | O(log n) |   O(log n)   |    O(log n)    |  O(n)   |

---
